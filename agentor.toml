# Agentor Configuration
#
# Supported providers: "claude", "openai", "openrouter", "groq", "claudecode"
#
# ┌─────────────┬──────────────────────────────┬──────────────┬───────────────┐
# │ Provider    │ model_id                     │ Cost         │ api_base_url  │
# ├─────────────┼──────────────────────────────┼──────────────┼───────────────┤
# │ claudecode  │ sonnet                       │ Free (sub)   │ (not needed)  │
# │ openai      │ qwen2.5:7b                   │ Free (local) │ localhost:11434│
# │ openai      │ mistral:latest               │ Free (local) │ localhost:11434│
# │ groq        │ llama-3.3-70b-versatile      │ Free (limit) │ (default)     │
# │ openrouter  │ meta-llama/llama-3.3-70b-instruct:free │ Free (limit) │ (default) │
# │ claude      │ claude-sonnet-4-6            │ Paid         │ (default)     │
# └─────────────┴──────────────────────────────┴──────────────┴───────────────┘
#
# --- Presets (uncomment one) ---
#
# Ollama local - qwen2.5:7b (free, no API key, requires `ollama run qwen2.5:7b`)
# [model]
# provider = "openai"
# model_id = "qwen2.5:7b"
# api_key = "not-needed"
# api_base_url = "http://localhost:11434"
#
# Ollama local - mistral:latest (free, no API key, requires `ollama run mistral`)
# [model]
# provider = "openai"
# model_id = "mistral:latest"
# api_key = "not-needed"
# api_base_url = "http://localhost:11434"
#
# Groq cloud - llama-3.3-70b-versatile (free with rate limit, needs GROQ_API_KEY)
# [model]
# provider = "groq"
# model_id = "llama-3.3-70b-versatile"
# api_key = "${GROQ_API_KEY}"
#
# Claude Code session (free with subscription, uses local `claude` CLI)
# [model]
# provider = "claudecode"
# model_id = "sonnet"
# api_key = "not-needed"

# Active configuration:
[model]
provider = "groq"
model_id = "llama-3.3-70b-versatile"
api_key = "${GROQ_API_KEY}"
temperature = 0.7
max_tokens = 4096
max_turns = 5

data_dir = "./data"

# Gateway server settings
[server]
host = "0.0.0.0"
port = 3000

# TLS configuration (optional)
[server.tls]
enabled = false
cert_path = ""
key_path = ""
# mTLS: require client certificates
client_ca_path = ""

# Rate limiting & authentication
[security]
max_requests_per_second = 10.0
max_burst = 50.0
max_message_length = 100000
# API keys for authentication (empty = no auth required)
# api_keys = ["your-secret-key-1", "your-secret-key-2"]
api_keys = []

# Skills configuration
# Each [[skills]] entry loads a skill on startup.
# Native skills use `type = "native"`, WASM skills use `type = "wasm"`.

[[skills]]
name = "echo"
description = "Echoes the input message back"
type = "wasm"
path = "skills/echo-skill/target/wasm32-wasip1/release/echo-skill.wasm"
[skills.parameters_schema]
type = "object"
[skills.parameters_schema.properties]
[skills.parameters_schema.properties.message]
type = "string"
description = "The message to echo"
required = ["message"]
[skills.capabilities]
# echo skill needs no capabilities — fully sandboxed

# Example: a file-reading skill would declare capabilities like this:
# [[skills]]
# name = "file_reader"
# description = "Read files from allowed directories"
# type = "wasm"
# path = "skills/file-reader/target/wasm32-wasip1/release/file-reader.wasm"
# [skills.capabilities]
# file_read = ["/tmp", "/home/user/documents"]

# Markdown skills directory — .md files with YAML frontmatter
# Skills with `prompt_injection: true` are injected into the system prompt.
# Skills without it are available as callable tools.
markdown_skills_dir = "skills/markdown"

# Tool Groups — named sets of skills for progressive disclosure
# Default groups: minimal, coding, web, full
# You can define custom groups here:
# [[tool_groups]]
# name = "devops"
# description = "DevOps tools for CI/CD and deployment"
# skills = ["shell", "file_read", "file_write", "http_fetch"]

# MCP Server configuration
# Connect to MCP-compatible tool servers (e.g., filesystem, GitHub, database tools)
# Each [[mcp_servers]] entry spawns a subprocess and discovers its tools.
#
# [[mcp_servers]]
# command = "npx"
# args = ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"]
#
# [[mcp_servers]]
# command = "npx"
# args = ["-y", "@modelcontextprotocol/server-github"]
# [mcp_servers.env]
# GITHUB_PERSONAL_ACCESS_TOKEN = "${GITHUB_TOKEN}"

# Channel configuration
[channels.webchat]
enabled = true

[channels.telegram]
enabled = false
bot_token = "${TELEGRAM_BOT_TOKEN}"

[channels.slack]
enabled = false
bot_token = "${SLACK_BOT_TOKEN}"

[channels.discord]
enabled = false
bot_token = "${DISCORD_BOT_TOKEN}"
